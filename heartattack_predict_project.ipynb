{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmp/d6J+sbrHjqhqN9IG5g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mt508/machine-learning-/blob/main/heartattack_predict_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "MgRI5bfPEl_r"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Activation, LeakyReLU, ELU\n",
        "\n",
        "from tensorflow.keras import  layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from zlib import crc32\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"/content/Medicaldataset.csv\")"
      ],
      "metadata": {
        "id": "-SPuwVPSEzuN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.drop(columns=[\"CK-MB\",\"Troponin\"])"
      ],
      "metadata": {
        "id": "PbN4DE0YE2XM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from zlib import crc32\n",
        "\n",
        "# Example dataset\n",
        "# data = pd.read_csv(\"your_file.csv\")\n",
        "\n",
        "# Make sure data is a DataFrame\n",
        "print(type(data))\n",
        "\n",
        "# Function definitions\n",
        "def is_id_in_test_set(identifier, test_ratio):\n",
        "    return crc32(np.int64(identifier)) < test_ratio * 2**32\n",
        "\n",
        "def split_data_with_id(data, test_ratio, id_column):\n",
        "    ids = data[id_column]\n",
        "    in_test_set = ids.apply(lambda id_: is_id_in_test_set(id_, test_ratio))\n",
        "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
        "\n",
        "# Create artificial stable ID\n",
        "data[\"id\"] = np.arange(len(data))\n",
        "\n",
        "# Make a copy (optional)\n",
        "data_with_id = data.copy()\n",
        "\n",
        "# Train-test split\n",
        "train_set, test_set = split_data_with_id(data_with_id, 0.2, \"id\")\n",
        "\n",
        "print(train_set.head())\n",
        "print(test_set.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwViMtBYE5gG",
        "outputId": "b3e77803-77a9-4fc7-97b2-49598a5bfb10"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "   Age  Gender  Heart rate  Systolic blood pressure  Diastolic blood pressure  \\\n",
            "0   64       1          66                      160                        83   \n",
            "1   21       1          94                       98                        46   \n",
            "3   64       1          70                      120                        55   \n",
            "4   55       1          64                      112                        65   \n",
            "6   32       0          40                      179                        68   \n",
            "\n",
            "   Blood sugar    Result  id  \n",
            "0        160.0  negative   0  \n",
            "1        296.0  positive   1  \n",
            "3        270.0  positive   3  \n",
            "4        300.0  negative   4  \n",
            "6        102.0  negative   6  \n",
            "    Age  Gender  Heart rate  Systolic blood pressure  \\\n",
            "2    55       1          64                      160   \n",
            "5    58       0          61                      112   \n",
            "12   64       1          60                      199   \n",
            "16   86       0          73                      114   \n",
            "23   30       1          63                      110   \n",
            "\n",
            "    Diastolic blood pressure  Blood sugar    Result  id  \n",
            "2                         77        270.0  negative   2  \n",
            "5                         58         87.0  negative   5  \n",
            "12                        99         92.0  positive  12  \n",
            "16                        68         87.0  positive  16  \n",
            "23                        68        107.0  positive  23  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_copy=train_set.copy()\n",
        "X = train_copy.drop(columns=[\"Result\",\"id\"])\n",
        "# Target\n",
        "y = data[\"Result\"]\n",
        "\n",
        "# Encode target\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y)\n"
      ],
      "metadata": {
        "id": "8Bo_qq2PFFWp"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled_train = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "SCL3uw8qFi-W"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "dict(zip(unique, counts))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDPXV0PqOhVn",
        "outputId": "b17d4145-47e6-427f-84cd-933ef0eaf34c"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'negative': np.int64(407), 'positive': np.int64(648)}"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, ELU\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "\n",
        "model5 = Sequential([\n",
        "    Dense(64, input_shape=(6,)),\n",
        "    ELU(),\n",
        "\n",
        "    Dense(128),\n",
        "    BatchNormalization(),\n",
        "    ELU(),\n",
        "\n",
        "    Dense(64),\n",
        "    ELU(),\n",
        "\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model5.compile(\n",
        "    optimizer=AdamW(\n",
        "        learning_rate=5e-4,\n",
        "        weight_decay=0.001\n",
        "    ),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', Precision(name='precision')]\n",
        ")\n"
      ],
      "metadata": {
        "id": "lCXyDdQxq-du"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vil2jY-Y5FjL"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgcqBUlo5MFW",
        "outputId": "de3f3d01-84d6-41e1-db76-98592e7c818e"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.5272 - loss: 0.7586 - precision: 0.6344 - val_accuracy: 0.4906 - val_loss: 0.7033 - val_precision: 0.5660 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4665 - loss: 0.7790 - precision: 0.5858 - val_accuracy: 0.5189 - val_loss: 0.7082 - val_precision: 0.5962 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5322 - loss: 0.7198 - precision: 0.6362 - val_accuracy: 0.4811 - val_loss: 0.7072 - val_precision: 0.5600 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5099 - loss: 0.7336 - precision: 0.6151 - val_accuracy: 0.5377 - val_loss: 0.7012 - val_precision: 0.6111 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5472 - loss: 0.7199 - precision: 0.6300 - val_accuracy: 0.4906 - val_loss: 0.7019 - val_precision: 0.5660 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5374 - loss: 0.7142 - precision: 0.6474 - val_accuracy: 0.5283 - val_loss: 0.7029 - val_precision: 0.6038 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5626 - loss: 0.7035 - precision: 0.6528 - val_accuracy: 0.5189 - val_loss: 0.7116 - val_precision: 0.5926 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5389 - loss: 0.7434 - precision: 0.6126 - val_accuracy: 0.5377 - val_loss: 0.7069 - val_precision: 0.6154 - learning_rate: 2.5000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5543 - loss: 0.6957 - precision: 0.6484 - val_accuracy: 0.5094 - val_loss: 0.6934 - val_precision: 0.5882 - learning_rate: 2.5000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5584 - loss: 0.6972 - precision: 0.6569 - val_accuracy: 0.5189 - val_loss: 0.6961 - val_precision: 0.5833 - learning_rate: 2.5000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5459 - loss: 0.6992 - precision: 0.6373 - val_accuracy: 0.5283 - val_loss: 0.7014 - val_precision: 0.5932 - learning_rate: 2.5000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5597 - loss: 0.7056 - precision: 0.6448 - val_accuracy: 0.4906 - val_loss: 0.7130 - val_precision: 0.5636 - learning_rate: 2.5000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5105 - loss: 0.7074 - precision: 0.6303 - val_accuracy: 0.5283 - val_loss: 0.7050 - val_precision: 0.5932 - learning_rate: 1.2500e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5075 - loss: 0.7158 - precision: 0.6073 - val_accuracy: 0.5189 - val_loss: 0.7002 - val_precision: 0.5862 - learning_rate: 1.2500e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5614 - loss: 0.6916 - precision: 0.6570 - val_accuracy: 0.5283 - val_loss: 0.7054 - val_precision: 0.5932 - learning_rate: 1.2500e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5524 - loss: 0.7046 - precision: 0.6375 - val_accuracy: 0.5472 - val_loss: 0.7045 - val_precision: 0.6102 - learning_rate: 6.2500e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5208 - loss: 0.7000 - precision: 0.6362 - val_accuracy: 0.5189 - val_loss: 0.7011 - val_precision: 0.5833 - learning_rate: 6.2500e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5563 - loss: 0.6826 - precision: 0.6636 - val_accuracy: 0.5189 - val_loss: 0.6987 - val_precision: 0.5833 - learning_rate: 6.2500e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5699 - loss: 0.6935 - precision: 0.6710 - val_accuracy: 0.5283 - val_loss: 0.6971 - val_precision: 0.5932 - learning_rate: 3.1250e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5474 - loss: 0.6991 - precision: 0.6538 - val_accuracy: 0.5472 - val_loss: 0.6966 - val_precision: 0.6066 - learning_rate: 3.1250e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5288 - loss: 0.6978 - precision: 0.6309 - val_accuracy: 0.5377 - val_loss: 0.6987 - val_precision: 0.5938 - learning_rate: 3.1250e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_scaled_train.shape)\n",
        "print(y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ef_dOg25s5L",
        "outputId": "f547f311-22c8-4b21-b911-4019cda4b35c"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1055, 6)\n",
            "(1319,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After splitting\n",
        "train_copy = train_set.copy()\n",
        "test_copy  = test_set.copy()\n",
        "\n",
        "# Features\n",
        "X_train = train_copy.drop(columns=[\"Result\", \"id\"])\n",
        "X_test  = test_copy.drop(columns=[\"Result\", \"id\"])\n",
        "\n",
        "# Target\n",
        "y_train = train_copy[\"Result\"]\n",
        "y_test  = test_copy[\"Result\"]\n",
        "\n",
        "# Encode target\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train_ = le.fit_transform(y_train)\n",
        "y_test_  = le.transform(y_test)\n",
        "\n",
        "# Scale features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled_train_ = scaler.fit_transform(X_train)\n",
        "X_scaled_test_  = scaler.transform(X_test)\n",
        "\n",
        "print(X_scaled_train.shape, y_train.shape)\n",
        "print(X_scaled_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-fLV_4x598H",
        "outputId": "f27506dc-9d23-43da-8d1b-bca78e1f3abb"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1055, 6) (1055,)\n",
            "(264, 6) (264,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "\n",
        "model_ = Sequential([\n",
        "    Dense(64, activation=\"tanh\", input_shape=(6,), kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Dense(32, activation=\"tanh\", kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Dense(16, activation=\"tanh\"),\n",
        "\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\", Precision(name=\"precision\"), Recall(name=\"recall\")]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtDQIwWc6wUF",
        "outputId": "fdcec4d1-9d6c-4a9d-ed0c-73fd0bdf607d"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "cw = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "cw_dict = dict(enumerate(cw))\n",
        "print(\"Class weights:\", cw_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LNnDLlN6-uv",
        "outputId": "93b2da58-3491-4d88-bc52-c8cccca4972f"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: np.float64(1.296068796068796), 1: np.float64(0.8140432098765432)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "es = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=12,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=4,\n",
        "    factor=0.5,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "history = model_.fit(\n",
        "    X_scaled_train_, y_train_,\n",
        "    validation_split=0.15,\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    class_weight=cw_dict,\n",
        "    callbacks=[es, lr],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al6gRM9t7DN7",
        "outputId": "2b931a69-62aa-4175-b6a2-36a413d48b87"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.5562 - loss: 0.7614 - precision: 0.6593 - recall: 0.5575 - val_accuracy: 0.5849 - val_loss: 0.7130 - val_precision: 0.6923 - val_recall: 0.5625 - learning_rate: 0.0010\n",
            "Epoch 2/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5907 - loss: 0.7235 - precision: 0.6901 - recall: 0.6069 - val_accuracy: 0.5786 - val_loss: 0.7113 - val_precision: 0.6883 - val_recall: 0.5521 - learning_rate: 0.0010\n",
            "Epoch 3/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5878 - loss: 0.7102 - precision: 0.7070 - recall: 0.5835 - val_accuracy: 0.6038 - val_loss: 0.7092 - val_precision: 0.7324 - val_recall: 0.5417 - learning_rate: 0.0010\n",
            "Epoch 4/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6076 - loss: 0.7134 - precision: 0.7216 - recall: 0.5884 - val_accuracy: 0.6164 - val_loss: 0.7027 - val_precision: 0.7397 - val_recall: 0.5625 - learning_rate: 0.0010\n",
            "Epoch 5/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5863 - loss: 0.7319 - precision: 0.6933 - recall: 0.5863 - val_accuracy: 0.6164 - val_loss: 0.7013 - val_precision: 0.7333 - val_recall: 0.5729 - learning_rate: 0.0010\n",
            "Epoch 6/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5861 - loss: 0.7068 - precision: 0.7047 - recall: 0.5791 - val_accuracy: 0.6541 - val_loss: 0.6876 - val_precision: 0.7733 - val_recall: 0.6042 - learning_rate: 0.0010\n",
            "Epoch 7/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6108 - loss: 0.7082 - precision: 0.7129 - recall: 0.5908 - val_accuracy: 0.6289 - val_loss: 0.6885 - val_precision: 0.7284 - val_recall: 0.6146 - learning_rate: 0.0010\n",
            "Epoch 8/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6434 - loss: 0.6941 - precision: 0.7407 - recall: 0.6591 - val_accuracy: 0.6478 - val_loss: 0.6873 - val_precision: 0.7381 - val_recall: 0.6458 - learning_rate: 0.0010\n",
            "Epoch 9/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6175 - loss: 0.7123 - precision: 0.7169 - recall: 0.5989 - val_accuracy: 0.6164 - val_loss: 0.6891 - val_precision: 0.7108 - val_recall: 0.6146 - learning_rate: 0.0010\n",
            "Epoch 10/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6127 - loss: 0.6932 - precision: 0.7113 - recall: 0.6320 - val_accuracy: 0.6164 - val_loss: 0.6927 - val_precision: 0.7108 - val_recall: 0.6146 - learning_rate: 0.0010\n",
            "Epoch 11/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6134 - loss: 0.6915 - precision: 0.7003 - recall: 0.6281 - val_accuracy: 0.6289 - val_loss: 0.6928 - val_precision: 0.7176 - val_recall: 0.6354 - learning_rate: 0.0010\n",
            "Epoch 12/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6228 - loss: 0.7156 - precision: 0.6957 - recall: 0.6453 - val_accuracy: 0.6226 - val_loss: 0.6914 - val_precision: 0.7195 - val_recall: 0.6146 - learning_rate: 0.0010\n",
            "Epoch 13/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6534 - loss: 0.6953 - precision: 0.7503 - recall: 0.6574 - val_accuracy: 0.6226 - val_loss: 0.6902 - val_precision: 0.7143 - val_recall: 0.6250 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5958 - loss: 0.6981 - precision: 0.7109 - recall: 0.5972 - val_accuracy: 0.6226 - val_loss: 0.6862 - val_precision: 0.7195 - val_recall: 0.6146 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6330 - loss: 0.6796 - precision: 0.7523 - recall: 0.6239 - val_accuracy: 0.6352 - val_loss: 0.6909 - val_precision: 0.7209 - val_recall: 0.6458 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6016 - loss: 0.7117 - precision: 0.6968 - recall: 0.6280 - val_accuracy: 0.6289 - val_loss: 0.6922 - val_precision: 0.7176 - val_recall: 0.6354 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6619 - loss: 0.6766 - precision: 0.7599 - recall: 0.6587 - val_accuracy: 0.6352 - val_loss: 0.6923 - val_precision: 0.7209 - val_recall: 0.6458 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6134 - loss: 0.7072 - precision: 0.7106 - recall: 0.6349 - val_accuracy: 0.6164 - val_loss: 0.6877 - val_precision: 0.7059 - val_recall: 0.6250 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6441 - loss: 0.6859 - precision: 0.7294 - recall: 0.6661 - val_accuracy: 0.6289 - val_loss: 0.6861 - val_precision: 0.7176 - val_recall: 0.6354 - learning_rate: 2.5000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6343 - loss: 0.6831 - precision: 0.7427 - recall: 0.6366 - val_accuracy: 0.6352 - val_loss: 0.6854 - val_precision: 0.7262 - val_recall: 0.6354 - learning_rate: 2.5000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6216 - loss: 0.7007 - precision: 0.7226 - recall: 0.6310 - val_accuracy: 0.6415 - val_loss: 0.6890 - val_precision: 0.7294 - val_recall: 0.6458 - learning_rate: 2.5000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6353 - loss: 0.6923 - precision: 0.7568 - recall: 0.6382 - val_accuracy: 0.6289 - val_loss: 0.6878 - val_precision: 0.7126 - val_recall: 0.6458 - learning_rate: 2.5000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6033 - loss: 0.7016 - precision: 0.6951 - recall: 0.5924 - val_accuracy: 0.6289 - val_loss: 0.6900 - val_precision: 0.7176 - val_recall: 0.6354 - learning_rate: 2.5000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6369 - loss: 0.6967 - precision: 0.7345 - recall: 0.6283 - val_accuracy: 0.6415 - val_loss: 0.6925 - val_precision: 0.7294 - val_recall: 0.6458 - learning_rate: 2.5000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6442 - loss: 0.6969 - precision: 0.7485 - recall: 0.6391 - val_accuracy: 0.6164 - val_loss: 0.6923 - val_precision: 0.7059 - val_recall: 0.6250 - learning_rate: 1.2500e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6489 - loss: 0.6855 - precision: 0.7514 - recall: 0.6406 - val_accuracy: 0.6289 - val_loss: 0.6925 - val_precision: 0.7176 - val_recall: 0.6354 - learning_rate: 1.2500e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6321 - loss: 0.6812 - precision: 0.7387 - recall: 0.6501 - val_accuracy: 0.6478 - val_loss: 0.6924 - val_precision: 0.7381 - val_recall: 0.6458 - learning_rate: 1.2500e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6269 - loss: 0.6941 - precision: 0.7327 - recall: 0.6288 - val_accuracy: 0.6478 - val_loss: 0.6917 - val_precision: 0.7381 - val_recall: 0.6458 - learning_rate: 1.2500e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6412 - loss: 0.6839 - precision: 0.7281 - recall: 0.6458 - val_accuracy: 0.6415 - val_loss: 0.6921 - val_precision: 0.7294 - val_recall: 0.6458 - learning_rate: 6.2500e-05\n",
            "Epoch 30/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6227 - loss: 0.6819 - precision: 0.7423 - recall: 0.6134 - val_accuracy: 0.6415 - val_loss: 0.6915 - val_precision: 0.7294 - val_recall: 0.6458 - learning_rate: 6.2500e-05\n",
            "Epoch 31/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6299 - loss: 0.6812 - precision: 0.7171 - recall: 0.6534 - val_accuracy: 0.6226 - val_loss: 0.6910 - val_precision: 0.7093 - val_recall: 0.6354 - learning_rate: 6.2500e-05\n",
            "Epoch 32/200\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6297 - loss: 0.6812 - precision: 0.7283 - recall: 0.6345 - val_accuracy: 0.6289 - val_loss: 0.6905 - val_precision: 0.7176 - val_recall: 0.6354 - learning_rate: 6.2500e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nTKUtMkV7VLj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}